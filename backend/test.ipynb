{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/palaniappan-r/anaconda3/envs/OpenROAD-LLM/lib/python3.12/site-packages/google_crc32c/__init__.py:29: RuntimeWarning: As the c extension couldn't be imported, `google-crc32c` is using a pure python implementation that is significantly slower. If possible, please configure a c build environment and compile the extension\n",
      "  warnings.warn(_SLOW_CRC32C_WARNING, RuntimeWarning)\n",
      "/home/palaniappan-r/anaconda3/envs/OpenROAD-LLM/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Google VertexAI embeddings...\n",
      "Processing markdown docs...\n",
      "Processing [./data/markdown/ORFS_docs/installation]...\n",
      "./data/markdown/ORFS_docs/installation is not populated, returning empty list.\n",
      "Processing [./data/markdown/OR_docs/installation]...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Markdown files: 100%|██████████| 2/2 [00:00<00:00, 402.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing [./data/markdown/gh_discussions/Build]...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Markdown files: 100%|██████████| 14/14 [00:00<00:00, 341.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing [./data/markdown/gh_discussions/Installation]...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Markdown files: 100%|██████████| 6/6 [00:00<00:00, 671.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding ['./data/markdown/ORFS_docs/installation', './data/markdown/OR_docs/installation', './data/markdown/gh_discussions/Build', './data/markdown/gh_discussions/Installation'] to FAISS database...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gapic client context issue detected.This can occur due to parallelization.\n",
      "Gapic client context issue detected.This can occur due to parallelization.\n",
      "Gapic client context issue detected.This can occur due to parallelization.\n",
      "Gapic client context issue detected.This can occur due to parallelization.\n",
      "Using Google VertexAI embeddings...\n",
      "Processing markdown docs...\n",
      "Processing [./data/markdown/OR_docs/tools]...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Markdown files: 100%|██████████| 40/40 [00:00<00:00, 178.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding ['./data/markdown/OR_docs/tools'] to FAISS database...\n",
      "\n",
      "Gapic client context issue detected.This can occur due to parallelization.\n",
      "Gapic client context issue detected.This can occur due to parallelization.\n",
      "Gapic client context issue detected.This can occur due to parallelization.\n",
      "Gapic client context issue detected.This can occur due to parallelization.\n",
      "Processing markdown manpages...\n",
      "Processing [./data/markdown/manpages/man1]...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Markdown files: 100%|██████████| 1/1 [00:00<00:00, 277.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing [./data/markdown/manpages/man2]...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Markdown files: 100%|██████████| 204/204 [00:00<00:00, 544.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing [./data/markdown/gh_discussions/Query]...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Markdown files: 100%|██████████| 70/70 [00:00<00:00, 638.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing [./data/markdown/gh_discussions/Runtime]...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Markdown files: 100%|██████████| 49/49 [00:00<00:00, 352.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing [./data/markdown/gh_discussions/Documentation]...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Markdown files: 100%|██████████| 2/2 [00:00<00:00, 868.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding ['./data/markdown/manpages/man1', './data/markdown/manpages/man2', './data/markdown/gh_discussions/Query', './data/markdown/gh_discussions/Runtime', './data/markdown/gh_discussions/Documentation'] to FAISS database...\n",
      "\n",
      "Gapic client context issue detected.This can occur due to parallelization.\n",
      "Gapic client context issue detected.This can occur due to parallelization.\n",
      "Gapic client context issue detected.This can occur due to parallelization.\n",
      "Gapic client context issue detected.This can occur due to parallelization.\n",
      "Gapic client context issue detected.This can occur due to parallelization.\n",
      "Using Google VertexAI embeddings...\n",
      "Processing docs...\n",
      "Processing [./data/pdf/OpenSTA/OpenSTA_docs.pdf]...\n",
      "Adding [['./data/pdf/OpenSTA/OpenSTA_docs.pdf']] to FAISS database...\n",
      "\n",
      "Gapic client context issue detected.This can occur due to parallelization.\n",
      "Gapic client context issue detected.This can occur due to parallelization.\n",
      "Gapic client context issue detected.This can occur due to parallelization.\n",
      "Gapic client context issue detected.This can occur due to parallelization.\n",
      "Using Google VertexAI embeddings...\n",
      "Processing markdown docs...\n",
      "Processing [./data/markdown/ORFS_docs]...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Markdown files: 100%|██████████| 14/14 [00:00<00:00, 158.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not find source for data/markdown/ORFS_docs/Manpage.md\n",
      "Could not find source for data/markdown/ORFS_docs/mainREADME.md\n",
      "Could not find source for data/markdown/ORFS_docs/SupportedOS.md\n",
      "Could not find source for data/markdown/ORFS_docs/index2.md\n",
      "Processing [./data/markdown/OR_docs]...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Markdown files: 100%|██████████| 54/54 [00:00<00:00, 205.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing [./data/markdown/gh_discussions]...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Markdown files: 100%|██████████| 172/172 [00:00<00:00, 505.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding ['./data/markdown/ORFS_docs', './data/markdown/OR_docs', './data/markdown/gh_discussions'] to FAISS database...\n",
      "\n",
      "Gapic client context issue detected.This can occur due to parallelization.\n",
      "Gapic client context issue detected.This can occur due to parallelization.\n",
      "Gapic client context issue detected.This can occur due to parallelization.\n",
      "Gapic client context issue detected.This can occur due to parallelization.\n",
      "Gapic client context issue detected.This can occur due to parallelization.\n",
      "Processing markdown manpages...\n",
      "Processing [./data/markdown/manpages/man1]...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Markdown files: 100%|██████████| 1/1 [00:00<00:00, 287.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing [./data/markdown/manpages/man2]...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Markdown files: 100%|██████████| 204/204 [00:00<00:00, 542.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding ['./data/markdown/manpages/man1', './data/markdown/manpages/man2'] to FAISS database...\n",
      "\n",
      "Gapic client context issue detected.This can occur due to parallelization.\n",
      "Gapic client context issue detected.This can occur due to parallelization.\n",
      "Gapic client context issue detected.This can occur due to parallelization.\n",
      "Gapic client context issue detected.This can occur due to parallelization.\n",
      "Using Google VertexAI embeddings...\n",
      "Processing markdown docs...\n",
      "Processing [./data/markdown/manpages/man3]...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Markdown files: 100%|██████████| 2633/2633 [00:01<00:00, 1675.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing [./data/markdown/gh_discussions/Bug]...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Markdown files: 100%|██████████| 8/8 [00:00<00:00, 786.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding ['./data/markdown/manpages/man3', './data/markdown/gh_discussions/Bug'] to FAISS database...\n",
      "\n",
      "Gapic client context issue detected.This can occur due to parallelization.\n",
      "Gapic client context issue detected.This can occur due to parallelization.\n",
      "Gapic client context issue detected.This can occur due to parallelization.\n",
      "Gapic client context issue detected.This can occur due to parallelization.\n",
      "Gapic client context issue detected.This can occur due to parallelization.\n",
      "Using Google VertexAI embeddings...\n",
      "Process HTML docs...\n",
      "Processing [/home/palaniappan-r/Code/ORAssistant/backend/data/rtdocs/yosyshq.readthedocs.io/]...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading HTML files: 100%|██████████| 619/619 [01:08<00:00,  8.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding ['/home/palaniappan-r/Code/ORAssistant/backend/data/rtdocs/yosyshq.readthedocs.io/'] to FAISS database...\n",
      "\n",
      "Gapic client context issue detected.This can occur due to parallelization.\n",
      "Gapic client context issue detected.This can occur due to parallelization.\n",
      "Gapic client context issue detected.This can occur due to parallelization.\n",
      "Gapic client context issue detected.This can occur due to parallelization.\n",
      "\u001b[H\u001b[2J"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/palaniappan-r/anaconda3/envs/OpenROAD-LLM/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The method `BaseTool.__call__` was deprecated in langchain-core 0.1.47 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 16\u001b[0m\n\u001b[1;32m      9\u001b[0m inputs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m'\u001b[39m: [\n\u001b[1;32m     11\u001b[0m         (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m'\u001b[39m, user_question),\n\u001b[1;32m     12\u001b[0m     ]\n\u001b[1;32m     13\u001b[0m }\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m rg\u001b[38;5;241m.\u001b[39mgraph \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 16\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mrg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRetrieverGraph not initialized.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/OpenROAD-LLM/lib/python3.12/site-packages/langgraph/pregel/__init__.py:1070\u001b[0m, in \u001b[0;36mPregel.stream\u001b[0;34m(self, input, config, stream_mode, output_keys, input_keys, interrupt_before, interrupt_after, debug)\u001b[0m\n\u001b[1;32m   1068\u001b[0m     done, inflight \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(), \u001b[38;5;28mset\u001b[39m()\n\u001b[1;32m   1069\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m futures:\n\u001b[0;32m-> 1070\u001b[0m     done, inflight \u001b[38;5;241m=\u001b[39m \u001b[43mconcurrent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfutures\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1071\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1072\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_when\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcurrent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfutures\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFIRST_COMPLETED\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1073\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1074\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mmax\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_time\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmonotonic\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1075\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mend_time\u001b[49m\n\u001b[1;32m   1076\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[1;32m   1077\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1078\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1079\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m fut \u001b[38;5;129;01min\u001b[39;00m done:\n\u001b[1;32m   1080\u001b[0m         task \u001b[38;5;241m=\u001b[39m futures\u001b[38;5;241m.\u001b[39mpop(fut)\n",
      "File \u001b[0;32m~/anaconda3/envs/OpenROAD-LLM/lib/python3.12/concurrent/futures/_base.py:305\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(fs, timeout, return_when)\u001b[0m\n\u001b[1;32m    301\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m DoneAndNotDoneFutures(done, not_done)\n\u001b[1;32m    303\u001b[0m     waiter \u001b[38;5;241m=\u001b[39m _create_and_install_waiters(fs, return_when)\n\u001b[0;32m--> 305\u001b[0m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    306\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m fs:\n\u001b[1;32m    307\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m f\u001b[38;5;241m.\u001b[39m_condition:\n",
      "File \u001b[0;32m~/anaconda3/envs/OpenROAD-LLM/lib/python3.12/threading.py:655\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    653\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    654\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 655\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    656\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m~/anaconda3/envs/OpenROAD-LLM/lib/python3.12/threading.py:355\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    354\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 355\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    356\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    357\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "from src.api.routers import graphs\n",
    "\n",
    "rg = graphs.rg\n",
    "os.system('clear')\n",
    "\n",
    "while True:\n",
    "    user_question = \"what is cts?\"\n",
    "    inputs = {\n",
    "        'messages': [\n",
    "            ('user', user_question),\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    if rg.graph is not None:\n",
    "        output = list(rg.graph.stream(inputs))\n",
    "    else:\n",
    "        raise ValueError('RetrieverGraph not initialized.')\n",
    "\n",
    "        # if (\n",
    "        #     isinstance(output, list)\n",
    "        #     and len(output) > 2\n",
    "        #     and 'generate' in output[2]\n",
    "        #     and 'messages' in output[2]['generate']\n",
    "        #     and len(output[2]['generate']['messages']) > 0\n",
    "        # ):\n",
    "        #     llm_response = output[2]['generate']['messages'][0]\n",
    "        # else:\n",
    "        #     print('LLM response extraction failed')\n",
    "\n",
    "        # print(f'\\n{llm_response}\\nSources:\\n{urls}\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'output' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m tool \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[43moutput\u001b[49m[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m]\u001b[38;5;241m.\u001b[39mkeys())[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      2\u001b[0m srcs \u001b[38;5;241m=\u001b[39m output[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m][tool][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msources\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      3\u001b[0m urls \u001b[38;5;241m=\u001b[39m output[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m][tool][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124murls\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'output' is not defined"
     ]
    }
   ],
   "source": [
    "tool = list(output[-2].keys())[0]\n",
    "srcs = output[-2][tool]['sources']\n",
    "urls = output[-2][tool]['urls']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OpenROAD-LLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
