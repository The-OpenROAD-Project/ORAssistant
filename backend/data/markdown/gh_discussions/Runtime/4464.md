# Avoiding overallocation of CPU and memory for OpenROAD builds

Subcategory: Resource management

## Conversation

### oharboe
I am running into problems with too many OpenROAD binaries running in parallel when using Bazel ORFS layer.

I'm looking into whether I can get Bazel not to overuse CPUs in the system: https://groups.google.com/g/bazel-discuss/c/KVDcZ-EDfZw

What other options are there? Surely this is not a new problem. What does other types of toolchains do?

However, could and should OpenROAD be modified so that it communicates with other OpenROAD instances in the system and throttles usage to avoid overallocation of CPU and memory?

Idea:

- add new option to openroad `-limit <path>`
- this would cause openroad instances to communicate with eachother not to overallocate CPU and memory

### maliberty
This seems to be more about job scheduling than OR.  Usually a job scheduler will have some ability to specify the required resources for a job.   OR itself will allow you to give a max number of threads if that's helpful.

For example in [condor](https://htcondor.readthedocs.io/en/latest/users-manual/submitting-a-job.html):
```
request_cpus   = 1
request_memory = 1024M
request_disk   = 10240K
```

I don't think OR should try to solve this as you can run into the same issue between unrelated tools (yosys, klayout, or, etc).  

### oharboe
Turns out there is an infinite loop, probably, in DRC. I thought things ground to a halt because of CPU thrashing, but the detailed router might actually be stuck here. https://github.com/The-OpenROAD-Project/OpenROAD/issues/4466

If there is some performance degradation like 30-50% when running multiple detailed routing in parallel, that's tolerable.

